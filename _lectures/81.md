---
type: lecture

date: 2024-08-21T11:00:00+5:30

format_date: August 21, 2024 (Wednesday)

title: "8.1. Advanced Attention Mechanisms-I"

tldr: "Understanding KV Caching. Discussion on the efficient attention mechanisms &ndash; multi-query attention, grouped query attention, sliding window attention."

hide_from_announcments: false

links: 
    - url: /static_files/presentations/81.pdf
      name: slides
    - url: /static_files/presentations/81_scribe.pdf
      name: scribe
    - url: https://youtu.be/nH30ZshilMM
      name: video
      
thumbnail: /static_files/presentations/81.jpg
---

<!-- Other additional contents using markdown -->
**Suggested Readings:**
- [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150)
- [Fast Transformer Decoding: One Write-Head is All You Need](https://arxiv.org/abs/1911.02150)
- [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://arxiv.org/abs/2305.13245v3)
- [Transformers KV Caching Explained](https://medium.com/@joaolages/kv-caching-explained-276520203249)

