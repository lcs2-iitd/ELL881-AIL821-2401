---
type: lecture

date: 2024-10-21T11:00:00+4:30

format_date: October 21, 2024 (Monday)

title: "19. Reasoning in LLMs"

tldr: "Looking into different types of reasoning tasks and various techniques (like, Chain-of-Thought prompting, backward chaining, etc.) facilitating LLMs to solve these tasks. Overview of various reasoning benchmarks and discussion on whether LLMs can truly reason and plan, highlighting both current capabilities and limitations."

hide_from_announcments: false

links: 
    - url: /static_files/presentations/181.pdf
      name: slides
    - url: https://youtu.be/B4pRRD2f8tk
      name: video


thumbnail: /static_files/presentations/181.jpg
---
<!-- Other additional contents using markdown -->
**Suggested Readings:**
- [Natural Language Reasoning, A Survey](https://dl.acm.org/doi/pdf/10.1145/3664194)
- [Chain-of-Thought Prompting Elicits Reasoning in Large Language Models](https://arxiv.org/pdf/2201.11903)
- [Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning](https://arxiv.org/pdf/2210.12217)
- [The Reversal Curse: LLMs trained on "A is B" fail to learn "B is A"](https://arxiv.org/pdf/2309.12288)
- [Reasoning or Reciting? Exploring the Capabilities and Limitations of Language Models Through Counterfactual Tasks](https://aclanthology.org/2024.naacl-long.102.pdf)
- [Alice in Wonderland: Simple Tasks Showing Complete Reasoning Breakdown in State-Of-the-Art Large Language Models](https://arxiv.org/pdf/2406.02061)
- [On the Planning Abilities of Large Language Models: A Critical Investigation](https://arxiv.org/pdf/2305.15771)
- [Can Large Language Models Reason and Plan?](https://arxiv.org/pdf/2403.04121v2)
- [LLMs Can't Plan, But Can Help Planning in LLM-Modulo Frameworks](https://arxiv.org/pdf/2402.01817)
