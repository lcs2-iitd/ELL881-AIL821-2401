---
type: lecture

date: 2024-08-21T11:00:00+5:30

format_date: August 21, 2024 (Wednesday)

title: "7.2. Advanced Attention Mechanisms-I"

tldr: "Discussion on the advanced and efficient attention mechanisms &ndash; multi-query attention, grouped query attention, sliding window attention."

hide_from_announcments: false

links: 
    - url:/static_files/presentations/72.pdf
      name: slides
    - url: /static_files/presentations/72_scribe.pdf
      name: scribes
    - url: https://youtu.be/nH30ZshilMM
      name: video
      
thumbnail: /static_files/presentations/lec9.jpg
---
**Suggested Readings:**
- [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
- [Longformer: The Long-Document Transformer](https://arxiv.org/abs/2004.05150)
- [One Write-Head is All You Need](https://arxiv.org/abs/1911.02150)
- [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://arxiv.org/abs/2305.13245v3)
<!-- Other additional contents using markdown -->
