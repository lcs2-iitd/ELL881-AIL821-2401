---
type: lecture

date: 2024-09-07T10:00:00+4:30

format_date: September 7, 2024 (Saturday)

title: "13.2. Alignment of Language Models: Reward Maximization-II"

tldr: "Looking into different algorithms for training the policy model, which is the LLM, to maximize the reward &ndash; REINFORCE, PPO."

hide_from_announcments: false

links: 
    - url: /static_files/presentations/132.pdf
      name: slides


thumbnail: /static_files/presentations/132.jpg
---
<!-- Other additional contents using markdown -->
**Suggested Readings:**
