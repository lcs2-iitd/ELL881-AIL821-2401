---
type: lecture

date: 2024-10-14T11:00:00+4:30

format_date: October 14, 2024 (Monday)

title: "17.2. Multimodal Models-II"

tldr: "Discussion on text generation with multimodal inputs."

hide_from_announcments: false

links: 
    - url: /static_files/presentations/multimodal_2.pdf
      name: slides
    - url: https://youtu.be/IuNheUd_fZ4
      name: video

thumbnail: /static_files/presentations/multimodal_2.jpg
---
<!-- Other additional contents using markdown -->
**Suggested Readings:**
- [Multimodal Few-Shot Learning with Frozen Language Models](https://arxiv.org/pdf/2106.13884)
- [Flamingo: a Visual Language Model for Few-Shot Learning](https://arxiv.org/pdf/2204.14198)
- [BLIP: Bootstrapping Language-Image Pre-training for Unified Vision-Language Understanding and Generation](https://arxiv.org/pdf/2201.12086)
- [BLIP-2: Bootstrapping Language-Image Pre-training with Frozen Image Encoders and Large Language Models](https://arxiv.org/pdf/2301.12597)
- [mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connection](https://arxiv.org/pdf/2205.12005v2)
- [Visual Instruction Tuning](https://arxiv.org/pdf/2304.08485)
- [Video-LLaMA: An Instruction-tuned Audio-Visual Language Model for Video Understanding](https://arxiv.org/pdf/2306.02858)
- [MiniGPT-4: Enhancing Vision-Language Understanding with Advanced Large Language Models](https://arxiv.org/pdf/2304.10592)
