---
type: lecture

date: 2024-11-13T11:00:00+5:30

format_date: November 13, 2024 (Wednesday)

title: "24. Interpretability: Demystifying the Black-Box LMs"

tldr: "Discussion on various interpretability techniques to decipher the inner workings of LLMs."

hide_from_announcments: false

links: 
    - url: /static_files/presentations/240.pdf
      name: slides
    - url: /static_files/presentations/240_scribe.pdf
      name: scribe
    

thumbnail: /static_files/presentations/240.jpg
---
<!-- Other additional contents using markdown -->
**Suggested Readings:**
- [Probing Classifiers: Promises, Shortcomings, and Advances](https://arxiv.org/pdf/2102.12452)
- [Mechanistic?](https://arxiv.org/pdf/2410.09087)
- [Interpretability in the Wild: a Circuit for Indirect Object Identification in GPT-2 Small](https://openreview.net/pdf?id=NpsVSN6o4ul)
- [Towards Automated Circuit Discovery for Mechanistic Interpretability](https://arxiv.org/pdf/2304.14997)
- [Towards Best Practices of Activation Patching in Language Models: Metrics and Methods](https://arxiv.org/pdf/2309.16042)
- [Attribution Patching: Activation Patching At Industrial Scale](https://www.neelnanda.io/mechanistic-interpretability/attribution-patching)
- [In-context Learning and Induction Heads](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html)
- [How to think step-by-step: A mechanistic understanding of chain-of-thought reasoning](https://openreview.net/pdf?id=uHLDkQVtyC)
- [Patchscopes: A Unifying Framework for Inspecting Hidden Representations of Language Models](https://arxiv.org/pdf/2401.06102)
- [Towards Monosemanticity: Decomposing Language Models With Dictionary Learning](https://transformer-circuits.pub/2023/monosemantic-features/index.html)

