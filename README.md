# Large Language Models: Introduction and Recent Advances 
### Course Code: ELL881 / AIL821

## Course Description
The field of Natural Language Processing (NLP) has witnessed rapid progress in recent times, driven mainly by the design and development of Large Language Models (LLMs). With the increase in scale, LLMs exhibit various emergent properties, though there are conflicting opinions among researchers about these phenomena. Nonetheless, LLMs are proving to be useful and are becoming ubiquitous across numerous applications.

This advanced course aims to introduce the latest advancements in generative AI for text and is open to both undergraduate and graduate students. The course is structured into five modules: Basics, Architecture, Learnability, User Acceptability, and Ethics & Miscellaneous. Together, these modules will provide a comprehensive view of the different facets of LLMs.

Students should have a background in Machine Learning and be proficient in Python programming. At least some basic knowledge of Deep Learning and NLP is preferred. Through assignments and a course project, students will acquire the skills necessary to design, implement, and understand LLMs using the PyTorch framework.

### Pre-requisites

#### Mandatory
• Data Structures and Algorithms <br>
• Python Programming <br>
• Machine Learning <br>

#### Desirable
• Deep Learning <br>
• Natural Language Processing <br>

### Tentative Syllabus
• Course Introduction <br>
• Introduction to Natural Language Processing <br>
• Introduction to Language Models <br>
• Word Representation <br>
• Neural Language Models <br>
• Introduction to Transformer <br>
• Pre-training Strategies <br>
• Advanced Attention Mechanisms <br>
• Mixture of Experts <br>
• Scaling Laws <br>
• Instruction Fine-tuning and In-context Learning <br>
• Alignment <br>
• Efficient Adaptation of LLMs <br>
• Efficient Inference from LLMs <br>
• Retrieval Augmentation <br>
• Multilingual Language Models <br>
• Tool Augmentation <br>
• Reasoning <br>
• Vision Language Models <br>
• Long-context LLMs <br>
• Model Editing <br>
• Bias, Toxicity and Hallucination <br>
• Self-evolving LLMs <br>
• Interpreting the Inner Workings of LLMs <br>
• Beyond Transformers: State Space Models <br>
• Conclusion <br>

## Course Convener
**Tanmoy Chakraborty** <br>
Associate Professor <br>
Office: 3B-7 (Block III, 3rd Floor), <br>
Department of Electrical Engineering, <br>
Indian Institute of Technology Delhi <br>
IIT Delhi Main Rd, IIT Campus, Hauz Khas, New Delhi, Delhi 110016 <br>
E-Mail: tanchak@iitd.ac.in; chak.tanmoy.iit@gmail.com <br>
